{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data3/hop20001/.conda/envs/torchenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import warnings\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8832, -0.4831],\n",
      "         [ 0.2317,  0.8681]],\n",
      "\n",
      "        [[-0.1631,  0.4590],\n",
      "         [ 0.0352,  0.1240]]])\n",
      "tensor([[[0.8832, 0.0000],\n",
      "         [0.2317, 0.8681]],\n",
      "\n",
      "        [[0.0000, 0.4590],\n",
      "         [0.0352, 0.1240]]])\n"
     ]
    }
   ],
   "source": [
    "# Test partial function\n",
    "relu_inplace = partial(F.relu, inplace = True)\n",
    "batch_size, dim1, dim2 = 2, 2, 2\n",
    "shape = [batch_size, dim1, dim2]\n",
    "in_tensor = torch.Tensor(*shape)\n",
    "nn.init.uniform_(in_tensor, a = -1, b = 1)\n",
    "print(in_tensor)\n",
    "out_tensor = relu_inplace(in_tensor)\n",
    "print(out_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6670,  0.6534]]])\n",
      "tensor([[[0.0000, 0.6534]]], grad_fn=<AddBackward0>)\n",
      "None tensor([[0.0763, 0.9488]])\n",
      "None tensor([[0.5329, 0.3484]])\n",
      "Number of features 2\n",
      "Currently used features 0\n",
      "Current used:  Parameter containing:\n",
      "tensor([[0.0763, 0.9488]], requires_grad=True)\n",
      "Currently used features 1\n",
      "Current used:  Parameter containing:\n",
      "tensor([[0.5329, 0.3484]], requires_grad=True)\n",
      "Currently used features 0\n",
      "Current used:  Parameter containing:\n",
      "tensor([[0.0763, 0.9488]], requires_grad=True)\n",
      "Currently used features 1\n",
      "Current used:  Parameter containing:\n",
      "tensor([[0.5329, 0.3484]], requires_grad=True)\n",
      "tensor([[[0.0000, 0.6534]]], grad_fn=<AddBackward0>)\n",
      "None tensor([[0.0763, 0.9488]])\n",
      "None tensor([[0.5329, 0.3484]])\n"
     ]
    }
   ],
   "source": [
    "# test ReLU_masked model\n",
    "from models_util import *\n",
    "batch_size, dim1, dim2 = 1, 1, 2\n",
    "shape = [batch_size, dim1, dim2]\n",
    "in_tensor = torch.Tensor(*shape)\n",
    "nn.init.uniform_(in_tensor, a = -1, b = 1)\n",
    "print(in_tensor)\n",
    "model = ReLU_masked()\n",
    "for i in range(2):\n",
    "    in_tensor = model(in_tensor)\n",
    "print(in_tensor)\n",
    "for p in model.parameters():\n",
    "    print(p.name, p.data)\n",
    "model.init = 0\n",
    "print('Number of features', model.num_feature)\n",
    "for i in range(4):\n",
    "    print('Currently used features', model.current_feature)\n",
    "    # print(eval('model.alpha_aux_{}_0'.format(model.current_feature)))\n",
    "    in_tensor = model(in_tensor)\n",
    "print(in_tensor)\n",
    "for p in model.parameters():\n",
    "    print(p.name, p.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m model_build\n\u001b[1;32m     12\u001b[0m \u001b[39m# model_build(eval(model_name), model_util)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m model_Masked \u001b[39m=\u001b[39m get_my_code(model)\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mget_my_code\u001b[0;34m(base)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_my_code\u001b[39m(base):\n\u001b[0;32m----> 8\u001b[0m     \u001b[39mclass\u001b[39;00m \u001b[39mmodel_build\u001b[39;00m(base, model_util):\n\u001b[1;32m      9\u001b[0m         \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,):\n\u001b[1;32m     10\u001b[0m           \u001b[39mpass\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases"
     ]
    }
   ],
   "source": [
    "from models_util import *\n",
    "from models_cifar import *\n",
    "\n",
    "model_name = 'ResNet18'\n",
    "model = ResNet18()\n",
    "# def get_my_code(base):\n",
    "\n",
    "#     class model_build(base, model_util):\n",
    "#         def __init__(self,):\n",
    "#           pass\n",
    "#     return model_build\n",
    "# # model_build(eval(model_name), model_util)\n",
    "# model_Masked = get_my_code(model)\n",
    "config = 1\n",
    "model_util_new(model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (3): Linear(in_features=10, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "# Define your model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Sequential(\n",
    "        nn.Linear(10, 10),\n",
    "        nn.ReLU()\n",
    "    ),\n",
    "    nn.Linear(10, 10)\n",
    ")\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(1, 10)\n",
    "\n",
    "# Choose your replacement activation function\n",
    "replacement_fn = nn.Sigmoid()\n",
    "\n",
    "# Replace all ReLU functions with the replacement function\n",
    "def replace_relu(model):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.ReLU):\n",
    "            model._modules[name] = replacement_fn\n",
    "        else:\n",
    "            replace_relu(module)\n",
    "\n",
    "replace_relu(model)\n",
    "print(model)\n",
    "# Run the model\n",
    "output = model(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_v2(\n",
      "  (stacks): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): Sigmoid()\n",
      "    (2): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "    (3): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class model_v2(nn.Module):\n",
    "    def __init__(self):     \n",
    "        super(model_v2, self).__init__()\n",
    "        self.stacks = nn.Sequential(\n",
    "        nn.Linear(10, 10),\n",
    "        nn.ReLU(),\n",
    "        nn.Sequential(\n",
    "            nn.Linear(10, 10),\n",
    "            nn.ReLU()\n",
    "        ),\n",
    "        nn.Linear(10, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.stacks(x)\n",
    "        out = F.relu(out)\n",
    "\n",
    "model = model_v2()\n",
    "\n",
    "# Generate some random input data\n",
    "input_data = torch.randn(1, 10)\n",
    "\n",
    "# Choose your replacement activation function\n",
    "replacement_fn = nn.Sigmoid()\n",
    "\n",
    "# Replace all ReLU functions with the replacement function\n",
    "def replace_relu(model):\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.ReLU):\n",
    "            model._modules[name] = replacement_fn\n",
    "        else:\n",
    "            replace_relu(module)\n",
    "\n",
    "replace_relu(model)\n",
    "print(model)\n",
    "# Run the model\n",
    "output = model(input_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09ed53c31c4084b0592fb3928828ca5258593b9e37489b03328497df4e897e81"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
